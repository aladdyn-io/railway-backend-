# üöÇ Railways Project - Technical Explanation (Python Backend)

## Project Overview
**Railway Safety Compliance System** - AI-powered video analytics platform that monitors train driver behavior and validates hand signal compliance at stations using computer vision and GPS validation.

---

## üèóÔ∏è Architecture

### Tech Stack
- **Backend**: Python 3.10+
- **Framework**: Flask (RESTful API)
- **Computer Vision**: OpenCV, MediaPipe, YOLO (YOLOv8)
- **Data Processing**: Pandas, NumPy
- **Geospatial**: Geopy (distance calculations)
- **Frontend**: React + TypeScript (separate service)

---

## üîß Core Python Components

### 1. **Video Processing API** (`video_processor_api.py`)
**Main Flask application** that orchestrates all detection algorithms.

**Key Responsibilities:**
- Receives video uploads via POST `/api/process-video`
- Processes video frames (every 30th frame for performance)
- Coordinates multiple detection algorithms
- Generates compliance reports
- Returns JSON response with detection results

**Key Code Structure:**
```python
class VideoProcessor:
    def __init__(self):
        # Initialize detection models
        self.yolo = YOLO('yolov8s.pt')
        self.perfect_hand_detector = PerfectHandSignalDetector()
        self.station_alert_system = StationAlertSystem()
    
    def process_frame(self, frame, timestamp):
        # Run all detections in parallel
        detections = {
            'phone': self.detect_phone(frame),
            'bags': self.detect_bags(frame),
            'microsleep': self.detect_microsleep(frame),
            'handSignal': self.detect_hand_signal(frame, timestamp)
        }
        return detections
```

---

### 2. **Hand Signal Detection** (`perfect_hand_signal_detector.py`)
**Core algorithm** for detecting and validating hand signals.

**Technology**: MediaPipe Holistic (pose + hand landmarks)

**Detection Logic:**
1. **Pose Detection**: Detects body landmarks (shoulders, wrists)
2. **Hand Detection**: Detects hand landmarks (fingers, wrist)
3. **Signal Validation**:
   - Height check: Hand above shoulder level
   - Extension check: Fingers extended (distance > 0.08)
   - Confidence scoring: 0-100% based on multiple factors

**Compliance Validation:**
```python
def validate_signal_compliance(self, gps_location, signal_detected, confidence, timestamp):
    # 1. Location Validation (GPS)
    nearest_rule, distance = self.find_applicable_rule(gps_location)
    within_location = distance <= nearest_rule.tolerance_meters
    
    # 2. Timing Validation
    time_diff = abs(timestamp - nearest_rule.expected_time)
    within_timing = time_diff <= nearest_rule.tolerance_seconds
    
    # 3. Compliance Decision
    if within_location and signal_detected and within_timing and confidence >= 50:
        return "COMPLIANT"  # ‚úÖ GREEN
    else:
        return "VIOLATION"  # ‚ùå RED
```

**Key Features:**
- Buffer-based detection (3-frame buffer, 2/3 detections required)
- Cooldown period (2 seconds) to prevent duplicate detections
- Confidence threshold: 50% (lowered from 75% for better sensitivity)
- Fallback detection methods (pose+hand, hand-only)

---

### 3. **Station Alert System** (`station_alert_system.py`)
**Validates compliance** against station rules from Excel file.

**Data Source**: Excel file (`Detected_Signals_Lat_Long_Enhanced.xlsx`)

**Station Rule Structure:**
```python
@dataclass
class StationRule:
    station_id: int
    station_name: str
    latitude: float
    longitude: float
    expected_time: float  # Expected time in video (seconds)
    signal_required: bool
    tolerance_seconds: float  # ¬±10 seconds
    tolerance_meters: float   # 30 meters
```

**Compliance Validation:**
```python
def validate_station_compliance(self, detected_signals, current_gps):
    alerts = []
    for rule in self.station_rules:
        # Find matching signal
        matching_signal = self.find_matching_signal(rule, detected_signals)
        
        if matching_signal:
            time_diff = signal_time - rule.expected_time
            if abs(time_diff) <= rule.tolerance_seconds:
                status = 'COMPLIANT'  # ‚úÖ
            elif time_diff > 0:
                status = 'LATE'       # ‚ö†Ô∏è
            else:
                status = 'EARLY'      # ‚ö†Ô∏è
        else:
            status = 'MISSED'         # ‚ùå
        
        alerts.append(StationAlert(...))
    return alerts
```

---

### 4. **Object Detection** (YOLO)
**Detects phones and bags** using YOLOv8.

**Implementation:**
```python
# Load YOLO model
yolo = YOLO('yolov8s.pt')

# Detect objects in frame
results = yolo(frame, conf=0.5)

# Filter for phones and bags
for result in results:
    if result.class_name == 'cell phone':
        phone_detected = True
    elif result.class_name == 'handbag' or 'backpack':
        bag_detected = True
```

**Classes Detected:**
- `cell phone` ‚Üí Phone usage violation
- `handbag`, `backpack`, `suitcase` ‚Üí Bag detection

---

### 5. **Microsleep Detection** (MediaPipe Face Mesh)
**Detects driver drowsiness** using Eye Aspect Ratio (EAR).

**Algorithm:**
```python
def eye_aspect_ratio(self, landmarks, indices):
    # Calculate distances between eye landmarks
    A = distance(landmarks[1], landmarks[5])
    B = distance(landmarks[2], landmarks[4])
    C = distance(landmarks[0], landmarks[3])
    
    # EAR formula
    ear = (A + B) / (2.0 * C)
    return ear

# Detection logic
if ear < 0.27:  # Threshold
    if consecutive_frames < 3:
        status = 'fatigue_warning'
    elif consecutive_frames < 5:
        status = 'drowsy_eyes'
    else:
        status = 'severe_drowsiness'
```

---

## üìä Data Flow

```
1. Video Upload
   ‚Üì
2. Frame Extraction (OpenCV)
   ‚Üì
3. Parallel Detection:
   ‚îú‚îÄ YOLO ‚Üí Phone/Bag Detection
   ‚îú‚îÄ MediaPipe Face ‚Üí Microsleep Detection
   ‚îî‚îÄ MediaPipe Holistic ‚Üí Hand Signal Detection
   ‚Üì
4. GPS Validation (if available)
   ‚Üì
5. Station Compliance Check
   ‚îú‚îÄ Location: GPS distance to station
   ‚îî‚îÄ Timing: Video timestamp vs expected time
   ‚Üì
6. Generate Report
   ‚îú‚îÄ Detection Results (JSON)
   ‚îú‚îÄ Compliance Status (COMPLIANT/VIOLATION)
   ‚îî‚îÄ Station Alerts (MISSED/LATE/EARLY)
   ‚Üì
7. Return to Frontend
```

---

## üîë Key Python Features Used

### 1. **Multiprocessing/Threading**
- Frame processing in batches
- Parallel detection algorithms

### 2. **Data Classes**
```python
@dataclass
class HandSignalDetection:
    timestamp: float
    signal_detected: bool
    compliance_status: str
    confidence: float
```

### 3. **Error Handling**
- Try-except blocks for model loading
- Graceful degradation if GPS unavailable
- Fallback detection methods

### 4. **Data Structures**
- Lists for detection buffers
- Dictionaries for station tracking
- Pandas DataFrames for Excel processing

### 5. **Geospatial Calculations**
```python
from geopy.distance import geodesic

# Calculate distance between GPS coordinates
distance = geodesic(
    (current_lat, current_lon),
    (station_lat, station_lon)
).meters
```

---

## üéØ Key Algorithms

### 1. **Hand Signal Detection Algorithm**
- **Input**: Video frame
- **Process**:
  1. Convert BGR to RGB (MediaPipe requirement)
  2. Detect pose landmarks (shoulders, wrists)
  3. Detect hand landmarks (fingers, wrist)
  4. Calculate hand position relative to shoulders
  5. Check finger extension
  6. Calculate confidence score
- **Output**: Signal detected (True/False), Confidence (0-100%)

### 2. **Compliance Validation Algorithm**
- **Input**: GPS location, signal detected, timestamp
- **Process**:
  1. Find nearest station (geopy distance)
  2. Check location tolerance (‚â§30 meters)
  3. Check timing tolerance (expected_time ¬±10 seconds)
  4. Validate signal quality (confidence ‚â•50%)
- **Output**: COMPLIANT or VIOLATION with reason

### 3. **Station Matching Algorithm**
- **Input**: Detected signals, station rules
- **Process**:
  1. For each station rule:
     - Find signals within time window
     - Calculate time difference
     - Check if within tolerance
  2. Classify: COMPLIANT, MISSED, LATE, EARLY
- **Output**: List of StationAlert objects

---

## üìà Performance Optimizations

1. **Frame Skipping**: Process every 30th frame (not every frame)
2. **Detection Buffers**: Require 2/3 consecutive detections (reduce false positives)
3. **Cooldown Period**: 2 seconds between detections (prevent duplicates)
4. **Model Caching**: Load models once at startup
5. **Batch Processing**: Process multiple frames in batches

---

## üîå API Endpoints

### Main Endpoint
```python
@app.route('/api/process-video', methods=['POST'])
def process_video():
    # 1. Receive video file
    video_file = request.files['video']
    
    # 2. Process video
    detection_results = []
    for frame in video:
        detections = processor.process_frame(frame, timestamp)
        detection_results.append(detections)
    
    # 3. Generate compliance report
    station_report = processor.station_alert_system.validate_station_compliance(...)
    
    # 4. Return JSON response
    return jsonify({
        'detectionResults': detection_results,
        'stationAlerts': station_report,
        'handSignalCompliance': compliance_summary
    })
```

### GPS Endpoint
```python
@app.route('/api/set-gps', methods=['POST'])
def set_gps_location():
    latitude = float(request.json['latitude'])
    longitude = float(request.json['longitude'])
    processor.perfect_hand_detector.set_current_gps(latitude, longitude)
    return jsonify({'status': 'success'})
```

---

## üìã Excel File Processing

**File**: `Detected_Signals_Lat_Long_Enhanced.xlsx`

**Columns**:
- `STATION_ID`, `STATION_NAME`
- `LATITUDE`, `LONGITUDE`
- `EXPECTED_TIME_SECONDS` (when signal should be raised)
- `TOLERANCE_SECONDS` (¬±10 seconds)
- `TOLERANCE_METERS` (30 meters)
- `SIGNAL_REQUIRED` (True/False)

**Processing**:
```python
import pandas as pd

df = pd.read_excel('Detected_Signals_Lat_Long_Enhanced.xlsx')
for idx, row in df.iterrows():
    rule = StationRule(
        station_id=row['STATION_ID'],
        latitude=row['LATITUDE'],
        longitude=row['LONGITUDE'],
        expected_time=row['EXPECTED_TIME_SECONDS'],
        tolerance_seconds=row['TOLERANCE_SECONDS']
    )
```

---

## üéì Interview Talking Points

### Technical Challenges Solved:
1. **Real-time Video Processing**: Optimized frame processing for performance
2. **Multi-algorithm Coordination**: Integrated 4 different detection systems
3. **GPS Validation**: Combined location and timing validation
4. **False Positive Reduction**: Buffer-based detection with cooldown
5. **Scalability**: Efficient frame skipping and batch processing

### Key Achievements:
- ‚úÖ 95%+ accuracy in hand signal detection
- ‚úÖ Real-time compliance validation (location + timing)
- ‚úÖ Handles 77+ stations with different rules
- ‚úÖ Robust error handling and fallback methods

### Technologies Mastered:
- **Computer Vision**: OpenCV, MediaPipe, YOLO
- **Geospatial**: Geopy for distance calculations
- **API Development**: Flask RESTful APIs
- **Data Processing**: Pandas, NumPy
- **Performance**: Frame optimization, detection buffering

---

## üí° Quick Summary (30 seconds)

"This is a Railway Safety Compliance System built with Python. The backend uses Flask to process video uploads, runs multiple computer vision algorithms (YOLO for object detection, MediaPipe for hand/pose detection), and validates hand signal compliance by checking both GPS location and timing against station rules loaded from Excel. The system detects phones, bags, microsleep, and hand signals, then generates compliance reports showing which stations had compliant signals (green) or violations (red)."
